# Data Engineering 101: Introduction to Data Engineering
Data engineering is the practice of designing and building systems for collecting, storing, and analyzing data at scale. It is a broad field with applications in every industry. Organizations have the ability to collect massive amounts of data and they need the right people and technology to ensure that the data are in a usable state by the time it reaches the data scientists and data analysts. In addition the data engineers makes the lives of the data scientists easier by cleaning and structuring them for usage in data analytics.

The amount of data an engineer works with varies with the organization, particularly with respect to its size. The bigger the organization, the more complex the analytics architecture, and the more data the engineer will be responsible for. Certain industries are more data-intensive, including healthcare, retail and financial services. Data engineers work in conjunction with data science teams while improving data transparency and enabling businesses to make more trustworthy business decisions.

## Data Engineers roles

The data engineering field is divided into several roles such as the generalists,pipeline-centric engineers and database-centric engineers. The generalists which are  generally focused on a typical work on small teams, doing end-to-end data collection, intake and processing data. They may have more skill than most data engineers, but less knowledge of systems architecture. The generalists data engineers might undertake for a small, metro-area food delivery service which would be to create a dashboard that displays the number of deliveries made each day for the past month and forecasts the delivery volume for the next month.

Pipeline-centric engineers are the data engineers typically work on a midsize data analytics team and more complicated data science projects across distributed systems. Midsize and large companies are more likely to need this role. A regional food delivery company might undertake a pipeline-centric project to create a tool for data scientists and analysts to search metadata for information about deliveries. They might look at distance driven and drive time required for deliveries in the past month, then use that data in a predictive algorithm to see what it means for the company's future business.

The Database-centric engineers are the data engineers that are tasked to implement, maintain and populate an analytics databases. This role typically exists at larger companies where data is distributed across several databases. The engineers work with pipelines, tune databases for efficient analysis and create table schemas using extract, transform, load (ETL) methods.

## ETL
ETL is a process in which data is copied from several sources into a single destination system.
A database-centric project at a large, multistate or national food delivery service would be to design an analytics database. In addition to creating the database, the data engineer would write the code to get data from where it's collected in the main application database into the analytics database.

## Data engineer responsibilities
Data engineers often work as part of an analytics team alongside data scientists. The engineers provide data in usable formats to the data scientists who run queries and algorithms against the information for predictive analytics, machine learning and data mining applications. Data engineers also deliver aggregated data to business executives and analysts and other end users so they can analyze it and apply the results to improving business operations.

Data engineers deal with both structured and unstructured data. Structured data is information that can be organized into a formatted repository like a database. Unstructured data such as text, images, audio and video files that doesn't conform to conventional data models. Data engineers must understand different approaches to data architecture and applications to handle both data types. A variety of big data technologies, such as open source data ingestion and processing frameworks, are also part of the data engineer's toolkit.

## Data Engineer Skills
Data engineers are skilled in programming languages such as C#, Java, Python, R, Ruby, Scala and SQL. Python, R and SQL are the three most important languages data engineers use. Engineers need a good understanding of ETL tools and REST-oriented APIs for creating and managing data integration jobs. These skills also help in providing data analysts and business users with simplified access to prepared data sets.

Data engineers must understand data warehouses and data lakes and how they work. For instance, Hadoop data lakes that offload the processing and storage work of established enterprise data warehouses support the big data analytics efforts data engineers work on. Data engineers must also understand NoSQL databases and Apache Spark systems, which are becoming common components of data workflows. Data engineers should have a knowledge of relational database systems as well, such as MySQL and PostgreSQL. Another focus is Lambda architecture, which supports unified data pipelines for batch and real-time processing.

Business intelligence (BI) platforms and the ability to configure them are another important focus for data engineers. With BI platforms, they can establish connections among data warehouses, data lakes and other data sources. Engineers must know how to work with the interactive dashboards BI platforms use. Although machine learning is more in the data scientist's or the machine learning engineer's skill set, data engineers must understand it, as well, to be able to prepare data for machine learning platforms. They should know how to deploy machine learning algorithms and gain insights from them.

Lastly, knowledge of Unix-based operating systems (OS) is important. Unix, Solaris and Linux provide functionality and root access that other OSes such as Mac OS and Windows -- don't. They give the user more control over the OS, which is useful for data engineers.


